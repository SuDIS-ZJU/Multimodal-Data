# Multimodal-Data
Multimodal Data Management and Database works.

Kindly let us know if we have missed any great papers. Thank you!

Table of Contents
=================

0. [Survey and Tutorial](#0-survey-and-tutorial)
1. [Multimodal Learning](#1-multimodal-learning)
2. [Multimodal Retrieval](#2-multimodal-retrieval)
3. [Tabular Data](#3-tabular-data)




## 0. Survey and Tutorial

### Survey

* [Recent advances and trends in multimodal deep learning: a review](https://arxiv.org/pdf/2105.11087.pdf)(arXiv.org 24 May 2021)-YZY
* [Retrieving Multimodal Information for Augmented Generation: A Survey](https://arxiv.org/pdf/2303.10868.pdf)(EMNLP2023)-YZY
* [Multi-Modal Hashing for Efficient Multimedia Retrieval: A Survey](https://www.computer.org/csdl/journal/tk/2024/01/10144360/1NJh8b1uwKs)(TKDE2023)-YZY
* [Multimodal machine learning: A survey and taxonomy](https://arxiv.org/pdf/1705.09406.pdf)(TPAMI2018)-YZY
* [How to Bridge the Gap between Modalities: A Comprehensive Survey on Multi-modal Large Language Model](https://arxiv.org/pdf/2311.07594.pdf)(arxiv2023)-YZY
* [A Survey of Multimodal Large Language Model from A Data-centric Perspective](https://arxiv.org/pdf/2405.16640)(arxiv May2024)-YZY


### Tutorial
* [Tutorial on MultiModal Machine Learning](https://cmu-multicomp-lab.github.io/mmml-tutorial/icml2023/)(ICML2023)-YZY

## 1. Multimodal Learning
   
* [Multimodal deep learning](https://arxiv.org/pdf/2301.04856.pdf)(ICML2011)-YZY
* [What Makes Multi-modal Learning Better than Single (Provably)](https://proceedings.neurips.cc/paper/2021/file/5aa3405a3f865c10f420a4a7b55cbff3-Paper.pdf)(nips2021)-YZY
* [GETTING ALIGNED ON REPRESENTATIONAL ALIGNMENT](https://arxiv.org/pdf/2310.13018.pdf)()-YZY
* [Provable Dynamic Fusion for Low-Quality Multimodal Data](https://proceedings.mlr.press/v202/zhang23ar/zhang23ar.pdf)(ICML2023)-YZY
* [Towards Semantic Consistency: Dirichlet Energy Driven Robust Multi-Modal Entity Alignment](https://epubs.siam.org/doi/pdf/10.1137/1.9781611977653.ch17)(ICDE2024)-YZY
  


## 2. Multimodal Retrieval 
* [MUST: An Effective and Scalable Framework for Multimodal Search of Target Modality](https://arxiv.org/pdf/2312.06397.pdf)(ICDE2024)-YZY
* [Efficient and Effective Multi-Modal Queries through Heterogeneous Network Embedding](https://ieeexplore.ieee.org/abstract/document/9328543)(TKDE2021)-YZY
* [Symphony: Towards natural language query answering over multi-modal data lakes](https://www.cidrdb.org/cidr2023/papers/p51-chen.pdf)(CIDR2023)-YZY
* [CAESURA: Language Models as Multi-Modal Query Planners](https://arxiv.org/pdf/2308.03424.pdf)(CIDR2024)-YZY
* [Scalable Deep Multimodal Learning for Cross-Modal Retrieval](https://dl.acm.org/doi/10.1145/3331184.3331213)(SIGIR2019)-YZY
* [Learned Data-aware Image Representations of Line Charts for Similarity Search](https://dl.acm.org/doi/pdf/10.1145/3588942)(SIGMOD2023)-YZY
* [Multimodal Graph Learning for Cross-Modal Retrieval](https://epubs.siam.org/doi/pdf/10.1137/1.9781611977653.ch17)(SDM2023)-YZY
* [End-to-end Knowledge Retrieval with Multi-modal Queries](https://aclanthology.org/2023.acl-long.478.pdf)(ACl2023)-YZY
* [Multimodal Chart Retrieval: A Comparison of Text, Table and Image Based Approaches](https://openreview.net/pdf?id=asB4B-9zHlo)(ACL2023)-YZY

### Benchmark


## 3.Tabular Data
* [TABERT: Pretraining for Joint Understanding of Textual and Tabular Data](https://arxiv.org/pdf/2005.08314)(ACL2020)-YZY
* [Learning Contextual Representations for Semantic Parsing with Generation-Augmented Pre-Training](https://openreview.net/pdf?id=asB4B-9zHlo)-YZY
